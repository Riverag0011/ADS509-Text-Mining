{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riverag0011/ADS509-Text-Mining/blob/main/Assignment_4_Political_Naive_Bayes_GR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 4: Political Naive Bayes\n",
        "\n",
        "Name: Gabi Rivera \\\n",
        "Course: ADS509-01 \\\n",
        "Date: 29Sep2024\n",
        "\n",
        "Code Reference: https://chatgpt.com/ and https://colab.research.google.com/"
      ],
      "metadata": {
        "id": "P6ZaeLfBTIzs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccTX6rFdVJhI"
      },
      "source": [
        "## Naive Bayes on Political Text\n",
        "\n",
        "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gj1qSFQsVJhK"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Feel free to include your text patterns functions\n",
        "#from text_functions_solutions import clean_tokenize, get_patterns\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfRytKlSUzz9",
        "outputId": "aea68a29-4e53-416d-b1fb-fb74f72f8ee8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "arNO6djOVJhL"
      },
      "outputs": [],
      "source": [
        "# Connect to the SQLite database\n",
        "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
        "convention_cur = convention_db.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check available tables\n",
        "table_query = convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = table_query.fetchall()\n",
        "print(tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLvrTFfbZQcy",
        "outputId": "5f0f12db-ab7a-4442-ea7e-fb5a495c9fff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('conventions',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first 5 rows from the conventions table\n",
        "query_results = convention_cur.execute(\"SELECT * FROM conventions LIMIT 5;\")\n",
        "rows = query_results.fetchall()\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu9T5Q0sZTvA",
        "outputId": "731e085c-60fd-40c3-83a2-824b65922d30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Democratic', 4, 'Unknown', 1, '00:00', 'Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', '127', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Speaker 1', 1, '00:33', 'I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', '41', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Speaker 2', 1, '00:59', 'Every four years, we come together to reaffirm our democracy. This year, we’ve come to save it.', '17', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Kerry Washington', 1, '01:07', 'We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.', '28', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Bernie Sanders', 1, '01:18', 'We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.', '22', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch one row to inspect column names\n",
        "query_results = convention_cur.execute(\"SELECT * FROM conventions LIMIT 1;\")\n",
        "columns = [description[0] for description in query_results.description]\n",
        "print(columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWprmEFZXYd",
        "outputId": "1842bbdb-11b1-4a35-c70a-e43984a7b8d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['party', 'night', 'speaker', 'speaker_count', 'time', 'text', 'text_len', 'file']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9noT7pdFVJhM"
      },
      "source": [
        "### Part 1: Exploratory Naive Bayes\n",
        "\n",
        "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text\n",
        "for each party and prepare it for use in Naive Bayes.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create convention data list\n",
        "convention_data = []\n",
        "\n",
        "# SQL query to pull party, speaker, and speech text from Democratic and Republican parties\n",
        "query_results = convention_cur.execute(\n",
        "    '''\n",
        "    SELECT party, speaker, text FROM conventions WHERE party IN ('Democratic', 'Republican') AND party != 'Other';\n",
        "    '''\n",
        ")\n",
        "\n",
        "# Populate convention_data list\n",
        "for row in query_results:\n",
        "    party = row[0]\n",
        "    speaker = row[1]\n",
        "    speech_text = row[2]\n",
        "    convention_data.append([party, speaker, speech_text])"
      ],
      "metadata": {
        "id": "pvU7BXQlU6ol"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the database connection\n",
        "convention_db.close()"
      ],
      "metadata": {
        "id": "js9xp6a2cXxZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ntqP3fVJhM"
      },
      "source": [
        "Let's look at some random entries and see if they look right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rVQ5T1uVJhM",
        "outputId": "e5f6e9f3-7f17-4bf9-ce80-f7aaa203a6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Republican', 'Rudy Giuliani', 'Although an agreement on action against police brutality would be very valuable for the country, it would also make President Trump appear to be an effective leader. They could have none of that. So, Black Lives Matter and Antifa sprang into action. In a flash, they hijacked the peaceful protests into vicious, brutal riots. Soon, protests turned into riots in many other American cities, almost all Democrat. Businesses were burned and crushed. People beaten, shot, and killed. Police officers routinely assaulted, badly beaten, and occasionally murdered. And, the police handcuffed by progressive Democrat mayors from doing anything, but observe the crimes and absorb the blows.']\n",
            "['Democratic', 'Kamala Harris', 'We will speak truths and we will act with the same faith in you that we ask you to place in us. We believe that our country, all of us will stand together for a better future. And we already are, we see it in the doctors, the nurses, the home healthcare workers and frontline workers who are risking their lives to save people they’ve never met.']\n",
            "['Democratic', 'Michelle Obama', 'Compassionate, resilient, decent people whose fortunes are bound up with one another. It is well past time for our leaders to once again reflect our truth. So it is up to us to add our voices and our votes to the course of history, echoing heroes, like John Lewis, who said, “When you see something that is not right, you must say something. You must do something.” That is the truest form of empathy. Not just feeling but doing, not just for ourselves or our kids, but for everyone, for all our kids. If we want to keep the possibility of progress alive in our time, if we want to be able to look our children in the eye after this election, we have got to reassert our place in American history, and we have got to do everything we can to elect my friend, Joe Biden, as the next president of the United States. Thank you all, God bless.']\n",
            "['Democratic', 'Speaker 35', 'John and Joe traveled thousands of miles together. Their families got to know each other, gathering for picnics in the Biden’s backyard.']\n",
            "['Democratic', 'Valerie Biden Owens', 'Beau was going to do fine things. I mean he had it all and then he got sick. The whole world tilted and it felt like we were all falling off.']\n",
            "['Democratic', 'Chuck Hagel', 'There’s something wrong with that. I mean, that’s a dereliction of duty. You’re failing the troops. You’re failing this country.']\n",
            "['Republican', 'I Lou Holtz', 'If I apply this test to Joe Biden, I can’t say yes to any of these three questions. I used to ask our athletes at Notre Dame, “If you did not show up, who would miss you and why?” Can you imagine what would happen to us if President Trump had not shown up in 2016 to run for president? I’m so glad he showed up. Thank you for showing up, Mr. President. I encourage everyone who loves this country, who loves America, to show up in November, for President Trump. Thank you.']\n",
            "['Democratic', 'Raumesh Akbari', 'The nurses in Memphis who came out of retirement to treat patients during this pandemic. You built this country.']\n",
            "['Democratic', 'Maya Harris', 'As the next.']\n",
            "['Republican', 'Speaker 96', 'Under Missouri law, you have a right to defend your home and the lives of your family.']\n"
          ]
        }
      ],
      "source": [
        "# Display some random entries to check the data\n",
        "random_entries = random.choices(convention_data, k=10)\n",
        "for entry in random_entries:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Create a function to clean and tokenize the speech text\n",
        "def clean_and_tokenize(text):\n",
        "    # Tokenize by splitting on whitespace\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Remove punctuation and filter out stopwords and non-alphabetic tokens\n",
        "    cleaned_tokens = [\n",
        "        token.casefold() for token in tokens\n",
        "        if token.isalpha() and token.casefold() not in stop_words\n",
        "    ]\n",
        "\n",
        "    # Join remaining tokens into a single string\n",
        "    return ' '.join(cleaned_tokens)\n",
        "\n",
        "# Clean and format the data\n",
        "cleaned_data = []\n",
        "for entry in convention_data:\n",
        "    party = entry[0]\n",
        "    speech_text = clean_and_tokenize(entry[2])\n",
        "    cleaned_data.append(f\"{speech_text}, {party}\")\n",
        "\n",
        "# Display some random entries to check the cleaned data\n",
        "random_entries = random.choices(cleaned_data, k=10)\n",
        "for entry in random_entries:\n",
        "    print(entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8ENuGikhuPg",
        "outputId": "94df8323-2589-4308-867b-4e1113dc2f0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe always cared military went one generals want share story christmas program playing ave one little girls burst tears teacher ran song played died teacher idea little father fought war night said got better help military, Democratic\n",
            "watched middle big one kids dropped everything take taught family top watched treat security waiters way would treat made feel special knew understands people make country told make effort get know remember stuck, Republican\n",
            "vice mike pence held tightly threads freedom woven leading principles alongside president nation experienced prosperity like never, Republican\n",
            ", Democratic\n",
            "started tea years american civil civil unrest division separated countrymen two opposing one determined keep people determined see people elizabeth cady stanton lucretia mott felt call fight selected delegates upon told could speak vote july three women met end formed coalition sole purpose gaining right women turn would free fight freedoms women across america united formed activist working tirelessly win vote american unconquerable susan anthony became one visible leaders registered voted every republican, Republican\n",
            "congressman matt speaking auditorium emptier joe daily nation full hearts clear see choice strength energy success president trump first president since reagan start new biden foolishly cheerled decades war without without president trump knows strongest fight distant fellow must fight save america may lose joe biden might even settle hashtag promoted aoc woketopians settle biden make extra movie directed horror film disarm empty lock home invite live next, Republican\n",
            "time next parents able look forward day send children school without fear gun, Democratic\n",
            "national, Republican\n",
            "giving people poor, Republican\n",
            ", Democratic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxg-HIuzVJhN"
      },
      "source": [
        "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**build our list of candidate words.**"
      ],
      "metadata": {
        "id": "PNAbpc6OlU0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you've already defined the word_cutoff and created feature_words\n",
        "word_cutoff = 5\n",
        "\n",
        "# Tokenize and create frequency distribution from cleaned_data\n",
        "tokens = [w for entry in cleaned_data for w in entry.split(',')[0].split()]\n",
        "word_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "feature_words = set()\n",
        "for word, count in word_dist.items():\n",
        "    if count > word_cutoff:\n",
        "        feature_words.add(word)\n",
        "\n",
        "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhW1pLgplvLU",
        "outputId": "3a8ae795-cece-4d56-9f63-9686665ba3c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With a word cutoff of 5, we have 1776 as features in the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define convention features\n",
        "def conv_features(text, fw):\n",
        "    \"\"\"Given some text, this returns a dictionary holding the\n",
        "       feature words.\n",
        "\n",
        "       Args:\n",
        "            * text: a piece of text in a continuous string. Assumes\n",
        "            text has been cleaned and case folded.\n",
        "            * fw: the *feature words* that we're considering. A word\n",
        "            in `text` must be in fw in order to be returned. This\n",
        "            prevents us from considering very rarely occurring words.\n",
        "\n",
        "       Returns:\n",
        "            A dictionary with the words in `text` that appear in `fw`.\n",
        "            Words are only counted once.\n",
        "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
        "            then this would return a dictionary of\n",
        "            {'quick' : True,\n",
        "             'fox' :    True}\n",
        "    \"\"\"\n",
        "\n",
        "    # Split the text into words\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Create a dictionary to hold the feature words found in text\n",
        "    ret_dict = {word: True for word in set(tokens) if word in fw}\n",
        "\n",
        "    return ret_dict"
      ],
      "metadata": {
        "id": "RiFZLgtTmoj5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assertions to test the function\n",
        "assert len(feature_words) > 0\n",
        "assert conv_features(\"donald is the president\", feature_words) == {'donald': True, 'president': True}\n",
        "assert conv_features(\"people are american in america\", feature_words) == {'america': True, 'american': True, 'people': True}"
      ],
      "metadata": {
        "id": "6Qp8FoISm6OQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsQSWvyzVJhO"
      },
      "source": [
        "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature sets using cleaned_data\n",
        "featuresets = [\n",
        "    (conv_features(text.split(',')[0].strip(), feature_words), text.split(',')[1].strip())\n",
        "    for text in cleaned_data\n",
        "]\n",
        "\n",
        "# Display some random entries to check the feature sets\n",
        "random_entries = random.choices(featuresets, k=10)\n",
        "for entry in random_entries:\n",
        "    print(entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEahXmV8pJ1L",
        "outputId": "d30658d3-f9fa-43e2-ceac-b5d302cc61ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'always': True}, 'Democratic')\n",
            "({}, 'Democratic')\n",
            "({'treat': True, 'matter': True, 'everyone': True}, 'Democratic')\n",
            "({'vice': True}, 'Republican')\n",
            "({'creating': True, 'understands': True, 'biden': True, 'joe': True, 'rule': True, 'really': True, 'move': True, 'best': True, 'us': True, 'toward': True, 'respects': True, 'wants': True, 'perfect': True}, 'Democratic')\n",
            "({'hope': True, 'american': True, 'ever': True, 'left': True}, 'Republican')\n",
            "({'august': True, 'moved': True, 'special': True, 'obama': True, 'went': True, 'kayla': True, 'army': True, 'learned': True, 'rescue': True, 'white': True, 'brutal': True, 'administration': True, 'everything': True, 'prepared': True, 'house': True, 'telling': True, 'president': True, 'something': True, 'operation': True, 'named': True, 'looking': True, 'months': True, 'mission': True, 'thank': True, 'time': True, 'military': True, 'difference': True, 'another': True, 'forward': True, 'kept': True, 'us': True, 'isis': True}, 'Republican')\n",
            "({'part': True, 'last': True, 'going': True, 'take': True, 'everybody': True, 'rural': True, 'thinking': True, 'care': True, 'put': True, 'doctor': True, 'country': True, 'could': True, 'insurance': True, 'health': True, 'finally': True, 'walked': True, 'affordable': True, 'wife': True, 'started': True, 'kind': True, 'months': True, 'somebody': True, 'worst': True, 'life': True, 'reached': True, 'came': True, 'near': True, 'stage': True, 'cancer': True, 'beau': True, 'name': True, 'day': True, 'coverage': True, 'remember': True, 'began': True, 'saved': True, 'lost': True, 'basically': True, 'got': True, 'dying': True, 'look': True, 'bed': True, 'brother': True, 'would': True}, 'Democratic')\n",
            "({'set': True, 'get': True, 'never': True, 'mind': True, 'way': True, 'think': True, 'anything': True, 'find': True, 'rule': True}, 'Democratic')\n",
            "({}, 'Democratic')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle and split into training and test sets\n",
        "random.seed(20220507)\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "test_size = 500\n",
        "test_set, train_set = featuresets[:test_size], featuresets[test_size:]"
      ],
      "metadata": {
        "id": "c4SjD3ZDrB3i"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Naive Bayes classifier\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "uRnrl10grKPv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate accuracy\n",
        "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
        "print(f\"Accuracy: {accuracy*100:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2ZAcDdsrOIh",
        "outputId": "1e76dc79-1d5b-4caa-c0bf-b86feec1c883"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 50.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGQh8FQqVJhO",
        "outputId": "3b62f869-880a-470a-8fb6-592845b0db93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
            "                   china = True           Republ : Democr =     26.5 : 1.0\n",
            "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
            "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
            "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
            "                supports = True           Republ : Democr =     16.1 : 1.0\n",
            "                   media = True           Republ : Democr =     15.9 : 1.0\n",
            "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
            "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
            "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
            "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
            "                 private = True           Republ : Democr =     11.9 : 1.0\n",
            "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
            "                 special = True           Republ : Democr =     10.9 : 1.0\n",
            "               amendment = True           Republ : Democr =     10.9 : 1.0\n",
            "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
            "                   trade = True           Republ : Democr =     10.5 : 1.0\n",
            "                 sanders = True           Democr : Republ =     10.1 : 1.0\n",
            "                   armed = True           Republ : Democr =      9.9 : 1.0\n",
            "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
            "                 liberal = True           Republ : Democr =      9.9 : 1.0\n",
            "                veterans = True           Republ : Democr =      9.9 : 1.0\n",
            "               wonderful = True           Republ : Democr =      9.9 : 1.0\n",
            "                 allowed = True           Republ : Democr =      9.7 : 1.0\n",
            "                   elect = True           Democr : Republ =      9.6 : 1.0\n"
          ]
        }
      ],
      "source": [
        "# Show the most informative features\n",
        "classifier.show_most_informative_features(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmSa5wLJVJhP"
      },
      "source": [
        "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
        "\n",
        "### My Observations\n",
        "\n",
        "It's odd to me that there are proportionally higher Republican hits. Only 4 out of 25 features are lead by Democrats. This might mean that the dataset is composed of higher Republican word frequency. Also, the accuracy score is at 50% so this adds to the point that classification model did not really performed well or better than just guessing half of the time. \\\n",
        "When it comes to patterns, it seems that frequent words for Republicans aligns with the party's rhetoric which are focused on law enforcement, concern over china, celebration of veterans, etc. Although there's noticeable fewer key Democratic features, words \"climate\" and \"vote\" seems to also align with the party's political focus. Progressive agenda on climate change and encouragement for voter's participation resonnates the Democratic parties political perspective.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz6p63y3VJhP"
      },
      "source": [
        "## Part 2: Classifying Congressional Tweets\n",
        "\n",
        "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
        "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
        "give you the query I used to pull out the tweets. Note that this DB has some big tables and\n",
        "is unindexed, so the query takes a minute or two to run on my machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wnfD7Vw8VJhP"
      },
      "outputs": [],
      "source": [
        "# Connect to the SQLite database\n",
        "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
        "cong_cur = cong_db.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check available tables\n",
        "cong_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cong_cur.fetchall()\n",
        "print(\"Available tables:\", tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e14vdsQrxRhQ",
        "outputId": "fd4d6c3c-4115-43f5-aa8c-b191254d32d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available tables: [('websites',), ('candidate_data',), ('tweets',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preview rows from a specified table\n",
        "def preview_table(table_name):\n",
        "    cong_cur.execute(f\"SELECT * FROM {table_name} LIMIT 5;\")\n",
        "    sample_rows = cong_cur.fetchall()\n",
        "    print(f\"Sample Rows from {table_name}:\", sample_rows)\n",
        "\n",
        "# Preview rows from each table\n",
        "preview_table('websites')\n",
        "preview_table('candidate_data')\n",
        "preview_table('tweets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfhi0pvhxTQE",
        "outputId": "86fdfe92-7eec-4fbd-ee3f-2d427eb4d2b1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Rows from websites: []\n",
            "Sample Rows from candidate_data: [(0, 'alex', 'Alabama', '5', 5, 'AL', 'AL05', 'Mo Brooks', 'Republican', 'https://brooks.house.gov/', 'RepMoBrooks', 'T', 64.0, 'M', 'Married', 'T', 'F', 'F', 'R+18', 'T', '65.53', 51960.0, 'S'), (1, 'alex', 'Alabama', '5', 5, 'AL', 'AL05', 'Peter Joffrion', 'Democratic', 'https://www.peterjoffrion.com/', 'peter_joffrion', 'F', 60.0, 'M', 'Single', 'T', 'F', 'F', 'R+18', 'T', '65.53', 51960.0, 'S'), (2, 'alex', 'California', '10', 10, 'CA', 'CA10', 'Jeff Denham', 'Republican', 'https://denham.house.gov/', 'RepJeffDenham', 'T', 51.0, 'M', 'Married', 'T', 'F', 'F', 'EVEN', 'T', None, 80817.0, 'W'), (3, 'alex', 'California', '10', 10, 'CA', 'CA10', 'Josh Harder', 'Democratic', 'https://www.harderforcongress.com/', 'joshua_harder', 'F', 30.0, 'M', 'Married', 'T', 'F', 'F', 'EVEN', 'T', None, 80817.0, 'W'), (4, 'alex', 'California', '27', 27, 'CA', 'CA27', 'Judy Chu', 'Democratic', 'https://chu.house.gov/', 'RepJudyChu', 'T', 65.0, 'F', 'Married', 'F', 'F', 'F', 'D+16', 'T', None, 63561.0, 'W')]\n",
            "Sample Rows from tweets: [('AL05', 'Mo Brooks', '2018-11-05 22:11:37.337695', '2018-11-02 18:16:13', 'RepMoBrooks', 0, '1058422543768535043', b'RT @yhn: .@RepMoBrooks: October jobs report shows continued \\xe2\\x80\\x98winning streak\\xe2\\x80\\x99 for American workers \\nBy @sean_yhn https://t.co/KCWSZWNOQi', None, None, 7, None), ('AL05', 'Mo Brooks', '2018-11-05 22:11:37.337695', '2018-11-02 15:32:04', 'RepMoBrooks', 0, '1058381232357212169', b'The winning streak for American workers continued in October with 250K new jobs added &amp; the unemployment rate of 3.7% holding steady. This great news comes on the heels of @USDOL report that wages jumped 3.1% over the last year, the highest increase in a decade. #JobsReport https://t.co/sj3yRWbgMk', None, None, 38, None), ('AL05', 'Mo Brooks', '2018-11-05 22:11:37.337695', '2018-11-01 22:44:39', 'RepMoBrooks', 0, '1058127706813095937', b'RT @realDonaldTrump: Illegal immigration affects the lives of all Americans. Illegal Immigration hurts American workers, burdens American t\\xe2\\x80\\xa6', None, None, 28773, None), ('AL05', 'Mo Brooks', '2018-11-05 22:11:37.337695', '2018-10-31 19:32:02', 'RepMoBrooks', 0, '1057716846110171137', b'Thanks to free-enterprise policies, companies are having to compete with each other for workers, &amp; it\\xe2\\x80\\x99s showing. Worker wages jumped 3.1% in the 3rd qtr, the biggest increase in a decade according to @USDOL. https://t.co/m5PdhG0ffZ', None, None, 9, None), ('AL05', 'Mo Brooks', '2018-11-05 22:11:37.337695', '2018-10-31 19:29:49', 'RepMoBrooks', 0, '1057716291472187394', b'RT @RepByrne: Support for my innovative solution to #BuildTheWall continues to grow! We are now up to 19 co-sponsors, and it becomes cleare\\xe2\\x80\\xa6', None, None, 11, None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preview column names for a specified table\n",
        "def preview_columns(table_name):\n",
        "    cong_cur.execute(f\"PRAGMA table_info({table_name});\")\n",
        "    columns = cong_cur.fetchall()\n",
        "    column_names = [column[1] for column in columns]\n",
        "    print(f\"Column Names from {table_name}:\", column_names)\n",
        "\n",
        "# Preview columns from each table\n",
        "preview_columns('websites')\n",
        "preview_columns('candidate_data')\n",
        "preview_columns('tweets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF8z0OMYxUoO",
        "outputId": "8e041be4-9b4b-4801-e93b-d954f1d79cf8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names from websites: ['district', 'candidate', 'pull_time', 'url', 'site_text']\n",
            "Column Names from candidate_data: ['index', 'student', 'state', 'district_num', 'formatted_dist_num', 'abbrev', 'district', 'candidate', 'party', 'website', 'twitter_handle', 'incumbent', 'age', 'gender', 'marital_status', 'white_non_hispanic', 'hispanic', 'black', 'partisian_lean_pvi', 'opposed', 'pct_urban', 'income', 'region']\n",
            "Column Names from tweets: ['district', 'candidate', 'pull_time', 'tweet_time', 'handle', 'is_retweet', 'tweet_id', 'tweet_text', 'likes', 'replies', 'retweets', 'tweet_ratio']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the query\n",
        "results = cong_cur.execute(\n",
        "    '''\n",
        "       SELECT DISTINCT\n",
        "              cd.candidate,\n",
        "              cd.party,\n",
        "              tw.tweet_text\n",
        "       FROM candidate_data cd\n",
        "       INNER JOIN tweets tw ON cd.twitter_handle = tw.handle\n",
        "           AND cd.candidate = tw.candidate\n",
        "           AND cd.district = tw.district\n",
        "       WHERE cd.party IN ('Republican','Democratic')\n",
        "           AND tw.tweet_text NOT LIKE '%RT%'\n",
        "    '''\n",
        ")\n",
        "\n",
        "# Store the results in a list\n",
        "results = list(results)\n",
        "\n",
        "# Display some sample results\n",
        "for row in results[:5]:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXmACs6fyzAE",
        "outputId": "1de5ba5a-09e9-4504-e839-5cd7702df905"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Mo Brooks', 'Republican', b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq')\n",
            "('Mo Brooks', 'Republican', b'\"Brooks: I Do Not Support America Raising, Training, and Arming a \\nRebel Army to Fight in Syria\\xe2\\x80\\x99s Civil War\" http://t.co/f2QFErMkD4')\n",
            "('Mo Brooks', 'Republican', b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6')\n",
            "('Mo Brooks', 'Republican', b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA')\n",
            "('Mo Brooks', 'Republican', b'\"Rep. Mo Brooks: NDAA Amnesty Amendment \\xe2\\x80\\x98Betrays Americans\\xe2\\x80\\x99\" via @BreitbartNews http://t.co/aflHYdUkuF')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv0M34NMVJhP",
        "outputId": "89f39b0e-fcb3-4015-9c75-be17f798bb33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good morning amjalexjohnson', 'Democratic']\n",
            "['rt alexckaufman top democrats repdonbeyer rep gerryconnolly ask epas busy inspector general open investigation', 'Democratic']\n",
            "['rt youngest canvasser day nico joshuaharder swingleft', 'Democratic']\n",
            "['patients ask federal government permission save lives great see righttotry signed law congratulations one biggest champions state rep nickzerwas able white house signing ceremony', 'Republican']\n",
            "['join markreardonkmox yesterday discuss taxreform important economy amp middleincome families also collected friendly bet goraiders', 'Republican']\n",
            "['focus kind america want friends neighbors children grandchildren world applaud rep joe kennedy focusing positive vision future', 'Democratic']\n",
            "['im happy push muchneeded work beltrami island state forest public use areas outdoors huge part minnesota life atv snowmobile access important recreation economy seventh', 'Democratic']\n",
            "['live cbakershow kfabnews', 'Republican']\n",
            "['support supporting grandparents raising grandchildren act seen many elderly patients raising young children must address ways help stepped raise grandchildren even already difficult circumstances', 'Democratic']\n",
            "['bills considering today touch spectrum issues driving opioidepidemic', 'Republican']\n"
          ]
        }
      ],
      "source": [
        "# Define preprocessing step for tweet comments\n",
        "def preprocess_tweet(tweet):\n",
        "    # Remove HTTPS links using regex\n",
        "    tweet = re.sub(r'https?://\\S+', '', tweet)\n",
        "\n",
        "    # Tokenize on whitespace\n",
        "    tokens = tweet.split()\n",
        "\n",
        "    # Remove punctuation and lowercase the tokens\n",
        "    tokens = [w.translate(str.maketrans('', '', string.punctuation)).lower() for w in tokens]\n",
        "\n",
        "    # Remove tokens that fail the isalpha test\n",
        "    tokens = [w for w in tokens if w.isalpha()]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "    # Join the remaining tokens into a string\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Initialize the list to hold tweet data\n",
        "tweet_data = []\n",
        "\n",
        "# Fill up tweet_data with cleaned and tokenized sublists\n",
        "for row in results:\n",
        "    candidate = row[0]\n",
        "    party = row[1]\n",
        "    tweet_text_bytes = row[2]\n",
        "\n",
        "    # Decode the tweet text\n",
        "    tweet_text = tweet_text_bytes.decode('utf-8')\n",
        "\n",
        "    # Preprocess the tweet text\n",
        "    cleaned_tweet = preprocess_tweet(tweet_text)\n",
        "\n",
        "    # Append a sublist to tweet_data\n",
        "    tweet_data.append([cleaned_tweet, party])\n",
        "\n",
        "# Display some random entries to check the cleaned data\n",
        "random_entries = random.choices(tweet_data, k=10)\n",
        "for entry in random_entries:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au2_3xaOVJhQ"
      },
      "source": [
        "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3qSuYKlrVJhQ"
      },
      "outputs": [],
      "source": [
        "random.seed(20201014)\n",
        "\n",
        "# Sample 10 random tweets from the tweet_data\n",
        "tweet_data_sample = random.choices(tweet_data, k=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet, party in tweet_data_sample :\n",
        "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
        "    # Fill in the right-hand side above with code that estimates the actual party\n",
        "\n",
        "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
        "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4bo7C4O4hW5",
        "outputId": "0dd4fd37-ca18-4b70-eab0-38019aa9c446"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's our (cleaned) tweet: mass shooting las vegas horrific act violence victims families thoughts prayers\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: early morning traveltuesday leaving dc\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: moderates iraq amp syria civilians weve enemies sides conflict assist either\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: rt natsecaction national security veterans demanding answers release confidential national security\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: buildthatwall\n",
            "Actual party is Republican and our classifer says Democratic.\n",
            "\n",
            "Here's our (cleaned) tweet: glad attend assure everyone could majority americans still stand traditional allies\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: cnn everyone wraps flag patriotism avoid discussion racism injustice kneeling honoring troops\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: applaud president trumps decision send national guard protect border congress support president including fully funding wall time stop playing politics national security united states fundthewall nationalguard\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: congress considers disaster relief spending year must include funding california fire relief listen remarks house floor\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: proud support oss helped vanquish malevolent enemies free ever faced\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIrz18CLVJhQ"
      },
      "source": [
        "Now that we've looked at it some, let's score a bunch and see how we're doing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dictionary of counts by actual party and estimated party\n",
        "parties = ['Republican', 'Democratic']\n",
        "results = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "# Set the number of tweets to score\n",
        "num_to_score = 10000\n",
        "random.shuffle(tweet_data)\n",
        "\n",
        "# Score the tweets\n",
        "for idx, tp in enumerate(tweet_data):\n",
        "    tweet, party = tp\n",
        "\n",
        "    # Get the estimated party\n",
        "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
        "\n",
        "    # Store the results in the dictionary\n",
        "    results[party][estimated_party] += 1\n",
        "\n",
        "    # Break the loop after scoring the specified number of tweets\n",
        "    if idx >= num_to_score:\n",
        "        break"
      ],
      "metadata": {
        "id": "4SjjHBAW5-0t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8QOjpviVJhQ",
        "outputId": "991e3bd8-982f-4ebc-cd70-03d1919584ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Party: Republican\n",
            "  Estimated Republican: 3580\n",
            "  Estimated Democratic: 560\n",
            "Actual Party: Democratic\n",
            "  Estimated Republican: 5028\n",
            "  Estimated Democratic: 833\n"
          ]
        }
      ],
      "source": [
        "# Display the results\n",
        "for actual_party in parties:\n",
        "    print(f\"Actual Party: {actual_party}\")\n",
        "    for estimated_party in parties:\n",
        "        print(f\"  Estimated {estimated_party}: {results[actual_party][estimated_party]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf1bC_cwVJhQ"
      },
      "source": [
        "### Reflections\n",
        "\n",
        "The same as the convention result at 50% accuracy. The congressional tweets performed poorly in correctly identifying Democratic text. There is definitely a class imbalance in both corpus. It will be better to balance the dataset before feeding the data into the classification model to improve the accuracy score. The Naive Bayes classfication model is definitely getting confused in distiguising the two parties apart."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}